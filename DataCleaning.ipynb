{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "import librosa\n",
    "from librosa import display,util,load,feature,stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mfcc: Mel-frequency cepstral coefficients\n",
    "* melspectrogram: Compute a Mel-scaled power spectrogram\n",
    "* chorma-stft: Compute a chromagram from a waveform or power spectrogram\n",
    "in music, the term chroma feature or chromagram closely relates to the twelve different pitch classes. Chroma-based features, which are also referred to as \"pitch class profiles\", are a powerful tool for analyzing music whose pitches can be meaningfully categorized and whose tuning approximates to the equal-tempered scale.\n",
    "* spectral_contrast: Compute spectral contrast\n",
    "* Spectral contrast is defined as the level difference between peaks and valleys in the spectrum\n",
    "* tonnetz: Computes the tonal centroid features (tonnetz), following the method of [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feat(audiofile_path):\n",
    "    # load in audio file\n",
    "    y, sr = load(audiofile_path) # y = audio file, sr = sample rate\n",
    "\n",
    "    # extract the various features of the audio\n",
    "    mfcc = np.mean(feature.mfcc(y = y, sr = sr, n_mfcc=40).T, axis = 0)  \n",
    "    mel = np.mean(feature.melspectrogram(y = y, sr = sr).T, axis = 0)\n",
    "    stft = np.abs(librosa.stft(y))\n",
    "    chroma = np.mean(feature.chroma_stft(S = stft, y = y, sr = sr).T, axis = 0)\n",
    "    contrast = np.mean(feature.spectral_contrast(S = stft, y = y, sr = sr).T, axis = 0)\n",
    "    tonnetz =  np.mean(feature.tonnetz(y = librosa.effects.harmonic(y), sr = sr).T, axis = 0)\n",
    "\n",
    "    return mfcc,chroma,mel,contrast,tonnetz # shape: (40,), (12,), (128,), (7,), (6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_master_dir(master_media_dir_path):\n",
    "    # Instatiate a dataframe the train audio features will be in \n",
    "    columns = ['id'] + ['mfcc']*40 + ['chroma']*12 + ['mel']*128 + ['contrast']*7 + ['tonnetz']*6\n",
    "    audio_df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    # Get data, extract features, append features into dataframe\n",
    "    ids = [f for f in listdir_nohidden(master_media_dir_path)] # get the filenames (ids) in the train_audio/ directory\n",
    "\n",
    "    for idd in ids:\n",
    "        id_path = master_media_dir_path  + str(idd)\n",
    "        id_sub_sample_folder = listdir_nohidden(id_path)\n",
    "\n",
    "        for mul_sample_one_id_folder in id_sub_sample_folder:\n",
    "            audio_sample_folder_path = id_path  + '/' + str(mul_sample_one_id_folder) + '/'\n",
    "\n",
    "            for audiofile in listdir_nohidden(audio_sample_folder_path):\n",
    "                audiofile_path = audio_sample_folder_path + str(audiofile)\n",
    "                mfcc,chroma,mel,contrast,tonnetz = extract_feat(audiofile_path)\n",
    "                features = np.hstack([mfcc,chroma,mel,contrast,tonnetz])\n",
    "\n",
    "                # get the id in integer form\n",
    "                idd_int = int(idd[2:])\n",
    "\n",
    "                # add id in the front of the features array\n",
    "                labelled = np.insert(features, 0, idd_int, axis = 0)\n",
    "                fill = np.empty((0,194))\n",
    "                row = np.vstack([fill,labelled]) # shape (1,193)\n",
    "\n",
    "                # put row in a dataframe\n",
    "                row_df = pd.DataFrame(row, columns = columns)\n",
    "\n",
    "                # append row_df into the dataframe\n",
    "                audio_df = audio_df.append(row_df, ignore_index = True)\n",
    "\n",
    "    audio_df.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    return audio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.robots.ox.ac.uk/~vgg/data/voxceleb/\n",
    "    \n",
    "VoxCeleb is an audio-visual dataset consisting of short clips of human speech, extracted from interview videos uploaded to YouTube\n",
    "\n",
    "VoxCeleb1 contains over 100,000 utterances for 1,251 celebrities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "audiofiles = listdir(\"//Mac/Home/Downloads/vox1_dev_wav_partad/wav/1/id10053/Ebts1VCIquw\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "audiofiles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "master_media_dir_path_1  = \"//Mac/Home/Downloads/vox1_dev_wav_partad/wav/1/\"\n",
    "print(master_media_dir_path_1)\n",
    "media_master_folder_1 = listdir(master_media_dir_path_1)\n",
    "print(len(media_master_folder_1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_df_1 = _read_master_dir(master_media_dir_path_1)\n",
    "sample_df_1.to_csv(\"sample1.csv\",index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "master_media_dir_path_2  = \"//Mac/Home/Downloads/vox1_dev_wav_partad/wav/2/\"\n",
    "print(master_media_dir_path_2)\n",
    "media_master_folder_2 = listdir(master_media_dir_path_2)\n",
    "print(len(media_master_folder_2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_df_2 = _read_master_dir(master_media_dir_path_2)\n",
    "sample_df_2.to_csv(\"sample2.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "master_media_dir_path_3  = \"//Mac/Home/Downloads/vox1_dev_wav_partad/wav/3/\"\n",
    "print(master_media_dir_path_3)\n",
    "media_master_folder_3= listdir(master_media_dir_path_3)\n",
    "print(len(media_master_folder_3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_df_3 = _read_master_dir(master_media_dir_path_3)\n",
    "sample_df_3.to_csv(\"sample3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "master_media_dir_path_4  = \"//Mac/Home/Downloads/vox1_dev_wav_partad/wav/4/\"\n",
    "print(master_media_dir_path_4)\n",
    "media_master_folder_4= listdir(master_media_dir_path_4)\n",
    "print(len(media_master_folder_4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_df_4 = _read_master_dir(master_media_dir_path_4)\n",
    "sample_df_4.to_csv(\"sample4.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_df_1 = pd.read_csv(\"sample1.csv\")\n",
    "sample_df_2 = pd.read_csv(\"sample2.csv\")\n",
    "sample_df_3 = pd.read_csv(\"sample3.csv\")\n",
    "sample_df_4 = pd.read_csv(\"sample4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_df = pd.concat([sample_df_1, sample_df_2, sample_df_3, sample_df_4])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_df.to_csv(\"sample_d.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
